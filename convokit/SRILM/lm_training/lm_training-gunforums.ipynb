{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, LanguageModel, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_corpus = Corpus(filename=\"/Users/calebchiam/Documents/GitHub/cs6742-fork/datasets/gun_debate_forum_corpus_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 2010\n",
      "Number of Utterances: 457973\n",
      "Number of Conversations: 4104\n"
     ]
    }
   ],
   "source": [
    "forum_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation({'_owner': <convokit.model.corpus.Corpus object at 0x12b0ff588>, '_id': 1, '_utterance_ids': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], '_usernames': None, '_meta': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(forum_corpus.iter_conversations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in forum_corpus.iter_conversations():\n",
    "    convo._utterance_ids = [str(i) for i in convo._utterance_ids]\n",
    "    convo._id = str(convo.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean\n",
    "\n",
    "clean_str = lambda s: clean(s,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=True,                  # replace all URLs with a special token\n",
    "    no_emails=True,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "    no_numbers=True,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # fully remove punctuation\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utt in forum_corpus.iter_utterances():\n",
    "    utt.id = str(utt.id)\n",
    "    utt.text = clean_str(utt.text)\n",
    "    utt.root = str(utt.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in forum_corpus.iter_users():\n",
    "    if 'lean' in user.meta:\n",
    "        user.meta['lean'] = user.meta['lean'].strip()\n",
    "    else:\n",
    "        user.meta['lean'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_corpus.dump(\"gun_debate_forum_corpus_fixed\", base_path=\"/Users/calebchiam/Documents/GitHub/cs6742-fork/datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fixed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_corpus = Corpus(filename=\"/Users/calebchiam/Documents/GitHub/cs6742-fork/datasets/gun_debate_forum_corpus_fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 2010\n",
      "Number of Utterances: 457973\n",
      "Number of Conversations: 4104\n"
     ]
    }
   ],
   "source": [
    "forum_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in forum_corpus.iter_conversations():\n",
    "    year = '20' + convo.meta['posted_date'].split('-')[-1]\n",
    "    if year == '20Yesterday':\n",
    "        year = '2019'\n",
    "    for utt in convo.iter_utterances():\n",
    "        utt.meta['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "leanings = defaultdict(int)\n",
    "for user in forum_corpus.iter_users():\n",
    "    if 'lean' in user.meta:\n",
    "        leanings[user.meta['lean']] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Libertarian': 117,\n",
       "             'Slightly Conservative': 49,\n",
       "             'Progressive': 77,\n",
       "             'Undisclosed': 428,\n",
       "             'Liberal': 105,\n",
       "             'Libertarian - Right': 83,\n",
       "             'Conservative': 215,\n",
       "             'Very Conservative': 87,\n",
       "             'Slightly Liberal': 56,\n",
       "             'Independent': 240,\n",
       "             'Centrist': 76,\n",
       "             'Other': 182,\n",
       "             'Socialist': 50,\n",
       "             'Libertarian - Left': 39,\n",
       "             None: 61,\n",
       "             'Private': 19,\n",
       "             'Moderate': 73,\n",
       "             'Very Liberal': 44,\n",
       "             'Communist': 9})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberal, Very Liberal, Progressive\n",
    "# Libertarian - Right, Conservative, Very Conservative\n",
    "# Independent, Centrist, Moderate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "year_to_utts = defaultdict(list)\n",
    "for utt in forum_corpus.iter_utterances():\n",
    "    year_to_utts[utt.meta['year']].append(utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019', 54714)\n",
      "('2018', 72113)\n",
      "('2017', 54629)\n",
      "('2015', 50248)\n",
      "('2014', 52090)\n",
      "('2013', 103768)\n",
      "('2016', 49123)\n",
      "('2012', 21288)\n"
     ]
    }
   ],
   "source": [
    "for year, utts in year_to_utts.items():\n",
    "    print((year, len(utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the set of liberal users\n",
    "# sample up to 3 utts per user per year\n",
    "# sum the utterances from all users for each year\n",
    "# use the minimum - some, to get a sample for every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "antigun_users = []\n",
    "progun_users = []\n",
    "for user in forum_corpus.iter_users():\n",
    "    lean = user.meta.get('lean', None)\n",
    "    if lean in {'Liberal', 'Very Liberal', 'Progressive'}:\n",
    "        antigun_users.append(user)\n",
    "    elif lean in {'Libertarian - Right', 'Conservative', 'Very Conservative'}:\n",
    "        progun_users.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in antigun_users + progun_users:\n",
    "    user.meta['year_utts'] = defaultdict(list)\n",
    "    for utt in user.iter_utterances():\n",
    "        user.meta['year_utts'][utt.meta['year']].append(utt)\n",
    "    \n",
    "    for year in user.meta['year_utts']:\n",
    "        if len(user.meta['year_utts'][year]) > 3: \n",
    "            user.meta['year_utts'][year] = sample(user.meta['year_utts'][year], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "antigun_year_utts = defaultdict(list)\n",
    "progun_year_utts = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in antigun_users:\n",
    "    for year, utts in user.meta['year_utts'].items():\n",
    "        antigun_year_utts[year].extend(utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019', 177)\n",
      "('2016', 159)\n",
      "('2015', 163)\n",
      "('2014', 166)\n",
      "('2013', 237)\n",
      "('2012', 129)\n",
      "('2018', 189)\n",
      "('2017', 143)\n"
     ]
    }
   ],
   "source": [
    "for year, utts in antigun_year_utts.items():\n",
    "    print((year, len(utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Minimum is 129 utts for antigun, so take 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in progun_users:\n",
    "    for year, utts in user.meta['year_utts'].items():\n",
    "        progun_year_utts[year].extend(utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019', 240)\n",
      "('2018', 319)\n",
      "('2017', 276)\n",
      "('2015', 261)\n",
      "('2014', 299)\n",
      "('2013', 392)\n",
      "('2016', 278)\n",
      "('2012', 225)\n"
     ]
    }
   ],
   "source": [
    "for year, utts in progun_year_utts.items():\n",
    "    print((year, len(utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum is 225 for progun, so take 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "antigun_sampled_utts = []\n",
    "for year, utts in antigun_year_utts.items():\n",
    "    antigun_sampled_utts.extend(sample(utts, 100))\n",
    "print(len(antigun_sampled_utts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "progun_sampled_utts = []\n",
    "for year, utts in progun_year_utts.items():\n",
    "    progun_sampled_utts.extend(sample(utts, 200))\n",
    "print(len(progun_sampled_utts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('progun_forum_corpus_full.txt', 'w') as f:\n",
    "    for utt in progun_sampled_utts:\n",
    "        for sentence in sent_tokenize(utt.text):\n",
    "            if len(sentence) > 5:\n",
    "                f.write(sentence)\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('antigun_forum_corpus_full.txt', 'w') as f:\n",
    "    for utt in progun_sampled_utts:\n",
    "        for sentence in sent_tokenize(utt.text):\n",
    "            if len(sentence) > 5:\n",
    "                f.write(sentence)\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## whole corpus training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in forum_corpus.iter_users():\n",
    "    user.meta['year_utts'] = defaultdict(list)\n",
    "    for utt in user.iter_utterances():\n",
    "        user.meta['year_utts'][utt.meta['year']].append(utt)\n",
    "    \n",
    "    for year in user.meta['year_utts']:\n",
    "        if len(user.meta['year_utts'][year]) > 3: \n",
    "            user.meta['year_utts'][year] = sample(user.meta['year_utts'][year], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_utts = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in forum_corpus.iter_users():\n",
    "    for year, utts in user.meta['year_utts'].items():\n",
    "        year_utts[year].extend(utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019', 1392)\n",
      "('2017', 1340)\n",
      "('2018', 1660)\n",
      "('2015', 1437)\n",
      "('2016', 1369)\n",
      "('2013', 2112)\n",
      "('2014', 1464)\n",
      "('2012', 1146)\n"
     ]
    }
   ],
   "source": [
    "for year, utts in year_utts.items():\n",
    "    print((year, len(utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_utts = []\n",
    "for year, utts in year_utts.items():\n",
    "    sampled_utts.extend(sample(utts, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('whole_forum_corpus_full.txt', 'w') as f:\n",
    "    for utt in sampled_utts:\n",
    "        for sentence in sent_tokenize(utt.text):\n",
    "            if len(sentence) > 5:\n",
    "                f.write(sentence)\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_utts_antigun_users = [len(list(user.iter_utterances())) for user in antigun_users]\n",
    "num_utts_progun_users = [len(list(user.iter_utterances())) for user in progun_users]\n",
    "num_utts_moderate_users = [len(list(user.iter_utterances())) for user in moderate_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_utts_antigun_users, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some people say a LOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_utts_progun_users, bins=20) # holy shit that guy at 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_utts_moderate_users, bins=20) # holy shit that guy at 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(num_utts_antigun_users))\n",
    "print(np.mean(num_utts_antigun_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(num_utts_progun_users))\n",
    "print(np.mean(num_utts_progun_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize, we take up to 5 utterances per user. If the user has <= 5 utterances, take all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progun_utts = []\n",
    "for user in progun_users:\n",
    "    user_utts = list(user.iter_utterances())\n",
    "    if len(user_utts) <= 5:\n",
    "        progun_utts.extend(user_utts)\n",
    "    else:\n",
    "        progun_utts.extend(sample(user_utts, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antigun_utts = []\n",
    "for user in antigun_users:\n",
    "    user_utts = list(user.iter_utterances())\n",
    "    if len(user_utts) <= 5:\n",
    "        antigun_utts.extend(user_utts)\n",
    "    else:\n",
    "        antigun_utts.extend(sample(user_utts, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_utts = []\n",
    "for user in moderate_users:\n",
    "    user_utts = list(user.iter_utterances())\n",
    "    if len(user_utts) <= 5:\n",
    "        moderate_utts.extend(user_utts)\n",
    "    else:\n",
    "        moderate_utts.extend(sample(user_utts, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(antigun_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(progun_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(moderate_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[utt.text for utt in antigun_utts[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[utt.text for utt in progun_utts[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return txt.replace(\"\\n\", \" \").replace('\\x92', \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progun_text = ''\n",
    "for utt in progun_utts:\n",
    "    if len(utt.text) >= 25:\n",
    "        if utt.text.endswith('.'):\n",
    "            progun_text += clean_text(utt.text) + ' '\n",
    "        else:\n",
    "            progun_text += clean_text(utt.text) + '. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antigun_text = ''\n",
    "for utt in antigun_utts:\n",
    "    if len(utt.text) >= 25:\n",
    "        if utt.text.endswith('.'):\n",
    "            antigun_text += clean_text(utt.text) + ' '\n",
    "        else:\n",
    "            antigun_text += clean_text(utt.text) + '. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_text = ''\n",
    "for utt in moderate_utts:\n",
    "    if len(utt.text) >= 25:\n",
    "        if utt.text.endswith('.'):\n",
    "            moderate_text += clean_text(utt.text) + ' '\n",
    "        else:\n",
    "            moderate_text += clean_text(utt.text) + '. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "all_text = ''\n",
    "for user in forum_corpus.iter_users():\n",
    "    user_utts = list(user.iter_utterances())\n",
    "    user_utts = [utt for utt in user_utts if len(utt.text) >= 25]\n",
    "    if len(user_utts) >= 3:\n",
    "        selected_utts = sample(user_utts, 3)\n",
    "    else:\n",
    "        selected_utts = user_utts\n",
    "    \n",
    "    for utt in selected_utts:\n",
    "        if utt.text.endswith('.'):\n",
    "            all_text += clean_text(utt.text) + ' '\n",
    "        else:\n",
    "            all_text += clean_text(utt.text) + '. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(progun_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(antigun_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(moderate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('progun_forum_corpus_full.txt', 'w') as f:\n",
    "    for sentence in sent_tokenize(progun_text):\n",
    "        if len(sentence) > 5:\n",
    "            f.write(sentence)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('antigun_forum_corpus_full.txt', 'w') as f:\n",
    "    for sentence in sent_tokenize(antigun_text):\n",
    "        if len(sentence) > 5:\n",
    "            f.write(sentence)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moderate_forum_corpus_full.txt', 'w') as f:\n",
    "    for sentence in sent_tokenize(moderate_text):\n",
    "        if len(sentence) > 5:\n",
    "            f.write(sentence)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('whole_forum_corpus_full.txt', 'w') as f:\n",
    "    for sentence in sent_tokenize(all_text):\n",
    "        if len(sentence) > 5:\n",
    "            f.write(sentence)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LanguageModel(SRILM_path='/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/srilm-1.7.3',\n",
    "                  working_dir='/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/',\n",
    "                  lm_output_path='whole_forum_full_new.lm',\n",
    "                  lm_type='laplace',\n",
    "                  count_output_path='whole_forum_counts.txt',\n",
    "                  order=2,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lm.train('whole_forum_corpus_full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LanguageModel(SRILM_path='/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/srilm-1.7.3',\n",
    "                  working_dir='/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/',\n",
    "                  lm_output_path='progun_forum_full_new.lm',\n",
    "                  lm_type='laplace',\n",
    "                  count_output_path='progun_forum_counts.txt',\n",
    "                  order=2,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lm.train('progun_forum_corpus_full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/progun_forum_full_new.lm: line 927: warning: non-zero probability for <unk> in closed-vocabulary LM\n",
      "file /Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/temp/1961692460021076566.txt: 1 sentences, 5 words, 0 OOVs\n",
      "0 zeroprobs, logprob= -18.79049 ppl= 1354.406 ppl1= 5729.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1354.406"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.str_perplexity(\"i love guns and freedom.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/progun_forum_full_new.lm: line 927: warning: non-zero probability for <unk> in closed-vocabulary LM\n",
      "file /Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/temp/7130116306463723547.txt: 1 sentences, 5 words, 0 OOVs\n",
      "0 zeroprobs, logprob= -17.89655 ppl= 961.0782 ppl1= 3795.863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "961.0782"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.str_perplexity(\"i love muffins and xlotl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/progun_forum_full_new.lm: line 927: warning: non-zero probability for <unk> in closed-vocabulary LM\n",
      "file /Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/temp/3495910162948954265.txt: 1 sentences, 3 words, 0 OOVs\n",
      "0 zeroprobs, logprob= -10.92274 ppl= 537.8788 ppl1= 4374.341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "537.8788"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.str_perplexity(\"i hate guns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/progun_forum_full_new.lm: line 927: warning: non-zero probability for <unk> in closed-vocabulary LM\n",
      "file /Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/temp/4482285361943563228.txt: 1 sentences, 9 words, 0 OOVs\n",
      "0 zeroprobs, logprob= -28.12978 ppl= 650.0974 ppl1= 1335.155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "650.0974"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.str_perplexity(\"we ought to have a right to arm ourselves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/progun_forum_full_new.lm: line 927: warning: non-zero probability for <unk> in closed-vocabulary LM\n",
      "file /Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/temp/6963016778896762089.txt: 1 sentences, 9 words, 0 OOVs\n",
      "0 zeroprobs, logprob= -26.91023 ppl= 490.9343 ppl1= 977.2957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490.9343"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.str_perplexity(\"we ought not have a right to arm ourselves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = LanguageModel(SRILM_path='/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/srilm-1.7.3',\n",
    "                  working_dir='/Users/calebchiam/Documents/GitHub/cs6742-fork/convokit/SRILM/dump/',\n",
    "                  lm_output_path='antigun_forum_full_new.lm',\n",
    "                  lm_type='laplace',\n",
    "                  count_output_path='antigun_forum_counts.txt',\n",
    "                  order=2,\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lm2.train('antigun_forum_corpus_full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406.6405"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.str_perplexity(\"i love guns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537.8788"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.str_perplexity(\"i hate guns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2.str_perplexity(\"We ought to have a right to arm ourselves.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2.str_perplexity(\"We ought not have a right to arm ourselves.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
